name: Checks

on:
  push:
    branches: [main, release]
  pull_request:
    branches: [main, release]
  workflow_dispatch:
  schedule:
    - cron: '30 3 * * *'

concurrency:
  group: checks-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

jobs:
  changes:
    runs-on: blacksmith-4vcpu-ubuntu-2404
    outputs:
      runtime: ${{ steps.filter.outputs.runtime }}
      runtime_electron: ${{ steps.filter.outputs.runtime_electron }}
      expo: ${{ steps.filter.outputs.expo }}
      demo: ${{ steps.filter.outputs.demo }}
      sync_matrix: ${{ steps.filter.outputs.sync_matrix }}
    steps:
      - uses: actions/checkout@v4
      - uses: dorny/paths-filter@v3
        id: filter
        with:
          filters: |
            runtime:
              - 'tests/runtime/**'
              - 'packages/dialect-wa-sqlite/**'
              - 'packages/dialect-better-sqlite3/**'
              - 'packages/dialect-d1/**'
              - 'packages/client/**'
              - 'packages/transport-http/**'
            runtime_electron:
              - 'tests/runtime/__tests__/electron.runtime.test.ts'
              - 'packages/dialect-electron-sqlite/**'
              - 'packages/dialect-sqlite3/**'
            expo:
              - 'tests/expo-app/**'
              - 'packages/dialect-expo-sqlite/**'
              - 'packages/core/src/kysely-serialize.ts'
            demo:
              - 'apps/demo/**'
              - 'packages/client/**'
              - 'packages/client-react/**'
              - 'packages/dialect-pglite/**'
              - 'packages/dialect-wa-sqlite/**'
              - 'packages/server/**'
              - 'packages/server-hono/**'
              - 'packages/server-dialect-postgres/**'
              - 'packages/server-dialect-sqlite/**'
              - 'packages/transport-ws/**'
              - 'packages/observability-sentry/**'
              - 'tests/runtime/**'
            sync_matrix:
              - 'packages/core/**'
              - 'packages/server/**'
              - 'packages/server-hono/**'
              - 'packages/client/**'
              - 'packages/client-react/**'
              - 'packages/transport-http/**'
              - 'packages/transport-ws/**'
              - 'packages/relay/**'
              - 'tests/integration/**'

  test:
    runs-on: blacksmith-4vcpu-ubuntu-2404
    timeout-minutes: 10
    steps:
      - uses: actions/checkout@v4
      - uses: ./.github/actions/setup-environment

      - name: Type checks and linting
        run: bun check

      - name: Unit and integration tests
        run: |
          set +e
          bun run test:coverage 2>&1 | tee test-results.txt
          exit_code=${PIPESTATUS[0]}
          set -e

          if [ "$exit_code" -eq 0 ]; then
            exit 0
          fi

          if [ "$exit_code" -eq 132 ] || [ "$exit_code" -eq 133 ] || grep -q "RuntimeError: Aborted(). Build with -sASSERTIONS" test-results.txt; then
            echo "Detected transient Bun/PGlite failure; retrying test suite once..."
            bun run test:coverage
            exit $?
          fi

          exit "$exit_code"

      - name: Upload coverage
        uses: codecov/codecov-action@v4
        if: always()
        with:
          files: ./coverage/lcov.info
          fail_ci_if_error: false

  integration-load:
    runs-on: blacksmith-4vcpu-ubuntu-2404
    timeout-minutes: 20
    steps:
      - uses: actions/checkout@v4
      - uses: ./.github/actions/setup-environment

      - name: Run integration load scenarios
        run: |
          set +e
          bun run test:load
          exit_code=$?
          set -e

          if [ "$exit_code" -eq 0 ]; then
            exit 0
          fi

          if [ "$exit_code" -eq 132 ] || [ "$exit_code" -eq 133 ]; then
            echo "Bun crashed with exit code $exit_code; retrying once..."
            bun run test:load
            exit $?
          fi

          exit "$exit_code"

  integration-full:
    needs: changes
    if: github.event_name == 'schedule' || github.event_name == 'workflow_dispatch' || github.event_name == 'push' || (github.event_name == 'pull_request' && needs.changes.outputs.sync_matrix == 'true')
    runs-on: blacksmith-4vcpu-ubuntu-2404
    timeout-minutes: 20
    steps:
      - uses: actions/checkout@v4
      - uses: ./.github/actions/setup-environment

      - name: Run full integration matrix
        run: bun run test:integration:full

  load-smoke-pr:
    needs: changes
    if: github.event_name == 'pull_request' && needs.changes.outputs.sync_matrix == 'true'
    runs-on: blacksmith-4vcpu-ubuntu-2404
    timeout-minutes: 25
    steps:
      - uses: actions/checkout@v4
      - uses: ./.github/actions/setup-environment
      - uses: grafana/setup-k6-action@v1

      - name: Run PR macro load smoke scenarios
        env:
          LOAD_NIGHTLY_SMOKE: true
          LOAD_NIGHTLY_SCENARIOS: reconnect-storm,mixed-workload
          LOAD_NIGHTLY_OUTPUT_JSON: load-pr-summary.json
          LOAD_NIGHTLY_RESULTS_DIR: .tmp/load-pr
          LOAD_SERVER_PORT: 3001
          LOAD_DB_DIALECT: sqlite
          SQLITE_PATH: ':memory:'
          SEED_RANDOM_SEED: 42
        run: |
          set +e
          bun run test:load:nightly 2>&1 | tee load-pr-results.txt
          exit_code=${PIPESTATUS[0]}
          set -e

          if [ "$exit_code" -eq 0 ]; then
            exit 0
          fi

          if [ "$exit_code" -eq 132 ] || [ "$exit_code" -eq 133 ]; then
            echo "Bun crashed with exit code $exit_code; retrying once..."
            bun run test:load:nightly
            exit $?
          fi

          exit "$exit_code"

      - name: Upload PR load smoke artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: load-pr-smoke-${{ github.run_id }}
          path: |
            load-pr-results.txt
            load-pr-summary.json
            .tmp/load-pr

  perf:
    if: github.event_name == 'pull_request' || github.event_name == 'push' || github.event_name == 'workflow_dispatch'
    runs-on: blacksmith-4vcpu-ubuntu-2404
    timeout-minutes: 25
    steps:
      - uses: actions/checkout@v4
      - uses: ./.github/actions/setup-environment

      - name: Run stable performance tests (5 runs)
        id: perf
        env:
          PERF_STABLE_RUNS: 5
          PERF_STABLE_OUTPUT_JSON: perf-summary.json
        run: |
          set +e
          bun --cwd tests/perf stable-ci 2>&1 | tee perf-results.txt
          exit_code=${PIPESTATUS[0]}
          set -e
          echo "exit_code=$exit_code" >> "$GITHUB_OUTPUT"

      - name: Extract regression report
        id: report
        run: |
          if ! grep -q "PERF_GATE_SYNC_REGRESSION=" perf-results.txt; then
            echo "execution_failed=true" >> $GITHUB_OUTPUT
          else
            echo "execution_failed=false" >> $GITHUB_OUTPUT
          fi

          if grep -q "PERF_GATE_SYNC_REGRESSION=true" perf-results.txt; then
            echo "has_regression=true" >> $GITHUB_OUTPUT
          else
            echo "has_regression=false" >> $GITHUB_OUTPUT
          fi

          if grep -q "PERF_GATE_SYNC_MISSING_BASELINE=true" perf-results.txt; then
            echo "has_missing_baseline=true" >> $GITHUB_OUTPUT
          else
            echo "has_missing_baseline=false" >> $GITHUB_OUTPUT
          fi

      - name: Upload perf artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: perf-results-${{ github.run_id }}
          path: |
            perf-results.txt
            perf-summary.json

      - name: Publish perf run summary
        if: always()
        run: |
          if [ ! -f perf-summary.json ]; then
            exit 0
          fi

          node - <<'NODE'
          const fs = require('fs');
          const summaryPath = process.env.GITHUB_STEP_SUMMARY;
          const report = JSON.parse(fs.readFileSync('perf-summary.json', 'utf8'));

          const lines = [];
          lines.push('## Perf Summary');
          lines.push('');
          lines.push(`- Runs: ${report.runCount}`);
          lines.push(`- Commit: ${report.commit ?? 'unknown'}`);
          lines.push(`- Regression: ${report.hasRegression ? 'yes' : 'no'}`);
          lines.push(`- Missing baseline: ${report.hasMissingBaseline ? 'yes' : 'no'}`);
          if (Array.isArray(report.baselineCommits) && report.baselineCommits.length > 0) {
            lines.push(`- Baseline commits: ${report.baselineCommits.join(', ')}`);
          }
          if (report.runEnvironment) {
            const env = report.runEnvironment;
            const envLabel = [env.platform, env.arch, `bun ${env.bunVersion}`]
              .filter(Boolean)
              .join(' / ');
            lines.push(`- Environment: ${env.source ?? 'unknown'} (${envLabel})`);
          }
          if (report.resources?.durationMs && report.resources?.cpuTotalMicros && report.resources?.maxRssBytes) {
            lines.push(
              `- Run resources (median): duration ${Number(report.resources.durationMs.median).toFixed(1)}ms, CPU ${(
                Number(report.resources.cpuTotalMicros.median) / 1000
              ).toFixed(1)}ms, max RSS ${(
                Number(report.resources.maxRssBytes.median) /
                (1024 * 1024)
              ).toFixed(1)} MiB`
            );
          }
          lines.push('');
          lines.push('| Metric | Baseline | Median | Change |');
          lines.push('|--------|----------|--------|--------|');

          for (const metric of report.metrics) {
            const baseline =
              metric.baseline === null ? 'N/A' : `${Number(metric.baseline).toFixed(1)}ms`;
            const median = `${Number(metric.aggregatedMedian).toFixed(1)}ms`;
            const change =
              metric.changePercent === null
                ? 'N/A'
                : `${metric.changePercent >= 0 ? '+' : ''}${Number(metric.changePercent).toFixed(1)}%`;
            lines.push(`| ${metric.metric} | ${baseline} | ${median} | ${change} |`);
          }

          fs.appendFileSync(summaryPath, `${lines.join('\n')}\n`);
          NODE

      - name: Comment PR with performance results
        if: always() && github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const results = fs.readFileSync('perf-results.txt', 'utf8');

            const lines = results.split('\n');
            const tableStart = lines.findIndex(l => l.includes('| Benchmark |'));
            const reportStart = lines.findIndex(l => l.includes('Performance'));

            let body = '## Performance Test Results\n\n';

            if (tableStart >= 0) {
              let tableEnd = tableStart;
              while (tableEnd < lines.length && lines[tableEnd].startsWith('|')) {
                tableEnd++;
              }
              body += lines.slice(tableStart, tableEnd).join('\n') + '\n\n';
            }

            if (reportStart >= 0) {
              body += lines.slice(reportStart).join('\n');
            }

            const { data: comments } = await github.rest.issues.listComments({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
            });

            const botComment = comments.find(c =>
              c.user.type === 'Bot' &&
              c.body.includes('Performance Test Results')
            );

            if (botComment) {
              await github.rest.issues.updateComment({
                comment_id: botComment.id,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body
              });
            } else {
              await github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body
              });
            }

      - name: Check previous perf job conclusion
        if: steps.report.outputs.has_regression == 'true'
        id: previous
        uses: actions/github-script@v7
        with:
          script: |
            const branch =
              context.eventName === 'pull_request'
                ? context.payload.pull_request.head.ref
                : context.ref.replace('refs/heads/', '');
            const { owner, repo } = context.repo;

            const runs = await github.rest.actions.listWorkflowRuns({
              owner,
              repo,
              workflow_id: 'checks.yml',
              branch,
              event: context.eventName,
              per_page: 20,
            });

            const previousRun = runs.data.workflow_runs.find(
              (run) => run.id !== context.runId && run.status === 'completed'
            );

            if (!previousRun) {
              core.setOutput('previous_regression', 'false');
              return;
            }

            const jobs = await github.rest.actions.listJobsForWorkflowRun({
              owner,
              repo,
              run_id: previousRun.id,
              per_page: 100,
            });

            const perfJob = jobs.data.jobs.find((job) => job.name === 'perf');
            const previousRegression = perfJob?.conclusion === 'failure';

            core.setOutput(
              'previous_regression',
              previousRegression ? 'true' : 'false'
            );
            core.setOutput('previous_run_url', previousRun.html_url ?? '');

      - name: Fail on perf runner execution error
        if: steps.report.outputs.execution_failed == 'true'
        run: |
          echo "Perf runner did not emit PERF_GATE markers. See perf-results.txt for details."
          exit 1

      - name: Fail on missing performance baseline
        if: steps.report.outputs.has_missing_baseline == 'true'
        run: |
          echo "Performance baseline missing for one or more metrics. Run bun test:perf:update-baseline and commit tests/perf/baseline.json."
          exit 1

      - name: Warn on first detected perf regression
        if: steps.report.outputs.has_regression == 'true' && steps.previous.outputs.previous_regression != 'true'
        run: |
          echo "::warning::Perf regression detected, but previous run did not fail perf gating. Soft-failing this run."
          if [ -n "${{ steps.previous.outputs.previous_run_url }}" ]; then
            echo "Previous run: ${{ steps.previous.outputs.previous_run_url }}"
          fi

      - name: Warn on consecutive performance regressions (push/manual)
        if: (github.event_name == 'push' || github.event_name == 'workflow_dispatch') && steps.report.outputs.has_regression == 'true' && steps.previous.outputs.previous_regression == 'true'
        run: |
          echo "::warning::Consecutive perf regressions detected on push/manual run."
          echo "Current run: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
          echo "Previous run: ${{ steps.previous.outputs.previous_run_url }}"

      - name: Fail on consecutive performance regressions (PR)
        if: github.event_name == 'pull_request' && steps.report.outputs.has_regression == 'true' && steps.previous.outputs.previous_regression == 'true'
        run: |
          echo "Sync performance regression detected in two consecutive runs."
          echo "Current run: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
          echo "Previous run: ${{ steps.previous.outputs.previous_run_url }}"
          exit 1

  perf-nightly:
    if: github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'
    runs-on: blacksmith-4vcpu-ubuntu-2404
    timeout-minutes: 45
    steps:
      - uses: actions/checkout@v4
      - uses: ./.github/actions/setup-environment

      - name: Run nightly stable performance tests (7 runs)
        env:
          PERF_STABLE_RUNS: 7
          PERF_STABLE_OUTPUT_JSON: perf-nightly-summary.json
        run: bun --cwd tests/perf stable-ci 2>&1 | tee perf-nightly-results.txt

      - name: Fetch historical perf summaries
        if: always()
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITHUB_REPOSITORY: ${{ github.repository }}
          GITHUB_RUN_ID: ${{ github.run_id }}
          PERF_HISTORY_WORKFLOW: checks.yml
          PERF_HISTORY_EVENT: schedule
          PERF_HISTORY_BRANCH: main
          PERF_HISTORY_ARTIFACT_PREFIX: perf-nightly-
          PERF_HISTORY_SUMMARY_FILE: perf-nightly-summary.json
          PERF_HISTORY_OUTPUT_DIR: perf-history
          PERF_HISTORY_MAX_FILES: 10
        run: bun --cwd tests/perf fetch-history 2>&1 | tee perf-history-fetch.txt

      - name: Run nightly trend/change-point analysis
        if: always()
        env:
          PERF_TREND_CURRENT_PATH: perf-nightly-summary.json
          PERF_TREND_HISTORY_DIR: perf-history
          PERF_TREND_OUTPUT_JSON: perf-nightly-trend.json
          PERF_TREND_MIN_HISTORY: 3
          PERF_TREND_DELTA_THRESHOLD: 0.2
          PERF_TREND_ROBUST_Z_THRESHOLD: 3
          PERF_TREND_FAIL_ON_CHANGE: false
        run: bun --cwd tests/perf trend-ci 2>&1 | tee perf-nightly-trend.txt

      - name: Warn on nightly perf change points
        if: always()
        run: |
          if [ ! -f perf-nightly-trend.json ]; then
            exit 0
          fi

          node - <<'NODE'
          const fs = require('fs');
          const trend = JSON.parse(fs.readFileSync('perf-nightly-trend.json', 'utf8'));
          if (trend.hasRegressionChangePoint) {
            const metrics = trend.metrics
              .filter((metric) => metric.regressionChangePoint)
              .map((metric) => metric.metric)
              .join(', ');
            console.log(`::warning::Nightly perf change-point detected for: ${metrics || 'unknown metric'}`);
          }
          NODE

      - name: Upload nightly perf artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: perf-nightly-${{ github.run_id }}
          path: |
            perf-nightly-results.txt
            perf-nightly-summary.json
            perf-nightly-trend.json
            perf-nightly-trend.txt
            perf-history-fetch.txt
            perf-history/index.json

      - name: Publish nightly perf summary
        if: always()
        run: |
          if [ ! -f perf-nightly-summary.json ]; then
            exit 0
          fi

          node - <<'NODE'
          const fs = require('fs');
          const summaryPath = process.env.GITHUB_STEP_SUMMARY;
          const report = JSON.parse(fs.readFileSync('perf-nightly-summary.json', 'utf8'));

          const lines = [];
          lines.push('## Nightly Perf Summary');
          lines.push('');
          lines.push(`- Runs: ${report.runCount}`);
          lines.push(`- Commit: ${report.commit ?? 'unknown'}`);
          lines.push(`- Regression: ${report.hasRegression ? 'yes' : 'no'}`);
          lines.push(`- Missing baseline: ${report.hasMissingBaseline ? 'yes' : 'no'}`);
          if (Array.isArray(report.baselineCommits) && report.baselineCommits.length > 0) {
            lines.push(`- Baseline commits: ${report.baselineCommits.join(', ')}`);
          }
          if (report.runEnvironment) {
            const env = report.runEnvironment;
            const envLabel = [env.platform, env.arch, `bun ${env.bunVersion}`]
              .filter(Boolean)
              .join(' / ');
            lines.push(`- Environment: ${env.source ?? 'unknown'} (${envLabel})`);
          }
          if (report.resources?.durationMs && report.resources?.cpuTotalMicros && report.resources?.maxRssBytes) {
            lines.push(
              `- Run resources (median): duration ${Number(report.resources.durationMs.median).toFixed(1)}ms, CPU ${(
                Number(report.resources.cpuTotalMicros.median) / 1000
              ).toFixed(1)}ms, max RSS ${(
                Number(report.resources.maxRssBytes.median) /
                (1024 * 1024)
              ).toFixed(1)} MiB`
            );
          }
          lines.push('');
          lines.push('| Metric | Baseline | Median | Change |');
          lines.push('|--------|----------|--------|--------|');

          for (const metric of report.metrics) {
            const baseline =
              metric.baseline === null ? 'N/A' : `${Number(metric.baseline).toFixed(1)}ms`;
            const median = `${Number(metric.aggregatedMedian).toFixed(1)}ms`;
            const change =
              metric.changePercent === null
                ? 'N/A'
                : `${metric.changePercent >= 0 ? '+' : ''}${Number(metric.changePercent).toFixed(1)}%`;
            lines.push(`| ${metric.metric} | ${baseline} | ${median} | ${change} |`);
          }

          fs.appendFileSync(summaryPath, `${lines.join('\n')}\n`);
          NODE

      - name: Publish nightly trend summary
        if: always()
        run: |
          if [ ! -f perf-nightly-trend.json ]; then
            exit 0
          fi

          node - <<'NODE'
          const fs = require('fs');
          const summaryPath = process.env.GITHUB_STEP_SUMMARY;
          const trend = JSON.parse(fs.readFileSync('perf-nightly-trend.json', 'utf8'));

          const lines = [];
          lines.push('## Nightly Perf Trend');
          lines.push('');
          lines.push(`- History files: ${trend.historySummaryCount}`);
          lines.push(`- Regression change-point: ${trend.hasRegressionChangePoint ? 'yes' : 'no'}`);
          lines.push(`- Insufficient history: ${trend.hasInsufficientHistory ? 'yes' : 'no'}`);
          lines.push('');
          lines.push('| Metric | Current | Hist Median | Delta | Robust Z | Hist N | Status |');
          lines.push('|--------|---------|-------------|-------|----------|--------|--------|');

          for (const metric of trend.metrics) {
            const current = Number(metric.current).toFixed(1) + 'ms';
            const histMedian =
              metric.historyMedian == null ? 'N/A' : Number(metric.historyMedian).toFixed(1) + 'ms';
            const delta =
              metric.deltaPercent == null
                ? 'N/A'
                : `${metric.deltaPercent >= 0 ? '+' : ''}${(Number(metric.deltaPercent) * 100).toFixed(1)}%`;
            const robustZ =
              metric.robustZ == null ? 'N/A' : Number(metric.robustZ).toFixed(2);
            const status = metric.insufficientHistory
              ? 'insufficient-history'
              : metric.regressionChangePoint
                ? 'regression-change-point'
                : metric.improvementChangePoint
                  ? 'improvement-change-point'
                  : 'stable';

            lines.push(
              `| ${metric.metric} | ${current} | ${histMedian} | ${delta} | ${robustZ} | ${metric.historyCount} | ${status} |`
            );
          }

          fs.appendFileSync(summaryPath, `${lines.join('\n')}\n`);
          NODE

  load-macro-nightly:
    if: github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'
    runs-on: blacksmith-4vcpu-ubuntu-2404
    timeout-minutes: 70
    steps:
      - uses: actions/checkout@v4
      - uses: ./.github/actions/setup-environment
      - uses: grafana/setup-k6-action@v1

      - name: Run nightly macro load suite
        env:
          LOAD_NIGHTLY_SMOKE: false
          LOAD_NIGHTLY_OUTPUT_JSON: load-nightly-summary.json
          LOAD_NIGHTLY_RESULTS_DIR: .tmp/load-nightly
          LOAD_SERVER_PORT: 3001
          LOAD_DB_DIALECT: sqlite
          SQLITE_PATH: ':memory:'
          SEED_ROWS: 250000
          SEED_USERS: 800
          SEED_RANDOM_SEED: 42
        run: bun run test:load:nightly 2>&1 | tee load-nightly-results.txt

      - name: Fetch historical load summaries
        if: always()
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITHUB_REPOSITORY: ${{ github.repository }}
          GITHUB_RUN_ID: ${{ github.run_id }}
          PERF_HISTORY_WORKFLOW: checks.yml
          PERF_HISTORY_EVENT: schedule
          PERF_HISTORY_BRANCH: main
          PERF_HISTORY_ARTIFACT_PREFIX: load-nightly-
          PERF_HISTORY_SUMMARY_FILE: load-nightly-summary.json
          PERF_HISTORY_OUTPUT_DIR: load-history
          PERF_HISTORY_MAX_FILES: 10
        run: bun --cwd tests/perf fetch-history 2>&1 | tee load-history-fetch.txt

      - name: Run nightly load trend/change-point analysis
        if: always()
        env:
          LOAD_TREND_CURRENT_PATH: load-nightly-summary.json
          LOAD_TREND_HISTORY_DIR: load-history
          LOAD_TREND_OUTPUT_JSON: load-nightly-trend.json
          LOAD_TREND_MIN_HISTORY: 3
          LOAD_TREND_DELTA_THRESHOLD: 0.2
          LOAD_TREND_ROBUST_Z_THRESHOLD: 3
          LOAD_TREND_FAIL_ON_CHANGE: false
        run: bun --cwd tests/load trend-ci 2>&1 | tee load-nightly-trend.txt

      - name: Warn on nightly load change points
        if: always()
        run: |
          if [ ! -f load-nightly-trend.json ]; then
            exit 0
          fi

          node - <<'NODE'
          const fs = require('fs');
          const trend = JSON.parse(fs.readFileSync('load-nightly-trend.json', 'utf8'));
          if (trend.hasRegressionChangePoint) {
            const metrics = trend.metrics
              .filter((metric) => metric.regressionChangePoint)
              .map((metric) => metric.metric)
              .join(', ');
            console.log(`::warning::Nightly load change-point detected for: ${metrics || 'unknown metric'}`);
          }
          NODE

      - name: Upload nightly load artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: load-nightly-${{ github.run_id }}
          path: |
            load-nightly-summary.json
            load-nightly-results.txt
            load-nightly-trend.json
            load-nightly-trend.txt
            load-history-fetch.txt
            load-history/index.json
            .tmp/load-nightly

      - name: Publish nightly load summary
        if: always()
        run: |
          if [ ! -f load-nightly-summary.json ]; then
            exit 0
          fi

          node - <<'NODE'
          const fs = require('fs');
          const summaryPath = process.env.GITHUB_STEP_SUMMARY;
          const report = JSON.parse(fs.readFileSync('load-nightly-summary.json', 'utf8'));

          const lines = [];
          lines.push('## Nightly Macro Load Summary');
          lines.push('');
          lines.push(`- Scenarios: ${report.scenarioCount}`);
          lines.push(`- Failed scenarios: ${report.failedScenarioCount}`);
          lines.push(`- Smoke mode: ${report.smokeMode ? 'yes' : 'no'}`);
          lines.push('');
          lines.push('| Scenario | Status | Duration | HTTP p95 | HTTP p99 | HTTP error rate |');
          lines.push('|----------|--------|----------|----------|----------|-----------------|');

          for (const scenario of report.scenarios ?? []) {
            const status = scenario.passed ? 'pass' : 'fail';
            const duration = `${(Number(scenario.durationMs) / 1000).toFixed(1)}s`;
            const httpP95 =
              scenario.metrics?.httpP95 == null
                ? 'N/A'
                : `${Number(scenario.metrics.httpP95).toFixed(1)}ms`;
            const httpP99 =
              scenario.metrics?.httpP99 == null
                ? 'N/A'
                : `${Number(scenario.metrics.httpP99).toFixed(1)}ms`;
            const errorRate =
              scenario.metrics?.httpErrorRate == null
                ? 'N/A'
                : `${(Number(scenario.metrics.httpErrorRate) * 100).toFixed(2)}%`;
            lines.push(`| ${scenario.id} | ${status} | ${duration} | ${httpP95} | ${httpP99} | ${errorRate} |`);
          }

          fs.appendFileSync(summaryPath, `${lines.join('\n')}\n`);
          NODE

      - name: Publish nightly load trend summary
        if: always()
        run: |
          if [ ! -f load-nightly-trend.json ]; then
            exit 0
          fi

          node - <<'NODE'
          const fs = require('fs');
          const summaryPath = process.env.GITHUB_STEP_SUMMARY;
          const trend = JSON.parse(fs.readFileSync('load-nightly-trend.json', 'utf8'));

          const lines = [];
          lines.push('## Nightly Load Trend');
          lines.push('');
          lines.push(`- History files: ${trend.historySummaryCount}`);
          lines.push(`- Regression change-point: ${trend.hasRegressionChangePoint ? 'yes' : 'no'}`);
          lines.push(`- Insufficient history: ${trend.hasInsufficientHistory ? 'yes' : 'no'}`);
          lines.push('');
          lines.push('| Metric | Current | Hist Median | Delta | Robust Z | Hist N | Status |');
          lines.push('|--------|---------|-------------|-------|----------|--------|--------|');

          for (const metric of trend.metrics) {
            const isRate = metric.metric.endsWith('/httpErrorRate');
            const current = isRate
              ? (metric.current == null ? 'N/A' : `${metric.current >= 0 ? '+' : ''}${(Number(metric.current) * 100).toFixed(1)}%`)
              : Number(metric.current).toFixed(1) + 'ms';
            const histMedian = metric.historyMedian == null
              ? 'N/A'
              : isRate
                ? `${metric.historyMedian >= 0 ? '+' : ''}${(Number(metric.historyMedian) * 100).toFixed(1)}%`
                : Number(metric.historyMedian).toFixed(1) + 'ms';
            const delta =
              metric.deltaPercent == null
                ? 'N/A'
                : `${metric.deltaPercent >= 0 ? '+' : ''}${(Number(metric.deltaPercent) * 100).toFixed(1)}%`;
            const robustZ =
              metric.robustZ == null ? 'N/A' : Number(metric.robustZ).toFixed(2);
            const status = metric.insufficientHistory
              ? 'insufficient-history'
              : metric.regressionChangePoint
                ? 'regression-change-point'
                : metric.improvementChangePoint
                  ? 'improvement-change-point'
                  : 'stable';

            lines.push(
              `| ${metric.metric} | ${current} | ${histMedian} | ${delta} | ${robustZ} | ${metric.historyCount} | ${status} |`
            );
          }

          fs.appendFileSync(summaryPath, `${lines.join('\n')}\n`);
          NODE

  load-pglite-nightly:
    if: github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'
    runs-on: blacksmith-4vcpu-ubuntu-2404
    timeout-minutes: 60
    steps:
      - uses: actions/checkout@v4
      - uses: ./.github/actions/setup-environment
      - uses: grafana/setup-k6-action@v1

      - name: Run nightly pglite contention load suite
        env:
          LOAD_NIGHTLY_SMOKE: false
          LOAD_NIGHTLY_SCENARIOS: reconnect-storm,mixed-workload,maintenance-churn
          LOAD_NIGHTLY_OUTPUT_JSON: load-nightly-pglite-summary.json
          LOAD_NIGHTLY_RESULTS_DIR: .tmp/load-nightly-pglite
          LOAD_SERVER_PORT: 3002
          LOAD_DB_DIALECT: pglite
          SEED_ROWS: 120000
          SEED_USERS: 600
          SEED_RANDOM_SEED: 42
        run: bun run test:load:nightly 2>&1 | tee load-nightly-pglite-results.txt

      - name: Fetch historical pglite load summaries
        if: always()
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITHUB_REPOSITORY: ${{ github.repository }}
          GITHUB_RUN_ID: ${{ github.run_id }}
          PERF_HISTORY_WORKFLOW: checks.yml
          PERF_HISTORY_EVENT: schedule
          PERF_HISTORY_BRANCH: main
          PERF_HISTORY_ARTIFACT_PREFIX: load-nightly-pglite-
          PERF_HISTORY_SUMMARY_FILE: load-nightly-pglite-summary.json
          PERF_HISTORY_OUTPUT_DIR: load-pglite-history
          PERF_HISTORY_MAX_FILES: 10
        run: bun --cwd tests/perf fetch-history 2>&1 | tee load-pglite-history-fetch.txt

      - name: Run nightly pglite load trend/change-point analysis
        if: always()
        env:
          LOAD_TREND_CURRENT_PATH: load-nightly-pglite-summary.json
          LOAD_TREND_HISTORY_DIR: load-pglite-history
          LOAD_TREND_OUTPUT_JSON: load-nightly-pglite-trend.json
          LOAD_TREND_MIN_HISTORY: 3
          LOAD_TREND_DELTA_THRESHOLD: 0.2
          LOAD_TREND_ROBUST_Z_THRESHOLD: 3
          LOAD_TREND_FAIL_ON_CHANGE: false
        run: bun --cwd tests/load trend-ci 2>&1 | tee load-nightly-pglite-trend.txt

      - name: Warn on nightly pglite load change points
        if: always()
        run: |
          if [ ! -f load-nightly-pglite-trend.json ]; then
            exit 0
          fi

          node - <<'NODE'
          const fs = require('fs');
          const trend = JSON.parse(fs.readFileSync('load-nightly-pglite-trend.json', 'utf8'));
          if (trend.hasRegressionChangePoint) {
            const metrics = trend.metrics
              .filter((metric) => metric.regressionChangePoint)
              .map((metric) => metric.metric)
              .join(', ');
            console.log(`::warning::Nightly pglite load change-point detected for: ${metrics || 'unknown metric'}`);
          }
          NODE

      - name: Upload nightly pglite load artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: load-nightly-pglite-${{ github.run_id }}
          path: |
            load-nightly-pglite-summary.json
            load-nightly-pglite-results.txt
            load-nightly-pglite-trend.json
            load-nightly-pglite-trend.txt
            load-pglite-history-fetch.txt
            load-pglite-history/index.json
            .tmp/load-nightly-pglite

      - name: Publish nightly pglite load summary
        if: always()
        run: |
          if [ ! -f load-nightly-pglite-summary.json ]; then
            exit 0
          fi

          node - <<'NODE'
          const fs = require('fs');
          const summaryPath = process.env.GITHUB_STEP_SUMMARY;
          const report = JSON.parse(fs.readFileSync('load-nightly-pglite-summary.json', 'utf8'));

          const lines = [];
          lines.push('## Nightly Pglite Load Summary');
          lines.push('');
          lines.push('- Dialect: pglite');
          lines.push(`- Scenarios: ${report.scenarioCount}`);
          lines.push(`- Failed scenarios: ${report.failedScenarioCount}`);
          lines.push(`- Smoke mode: ${report.smokeMode ? 'yes' : 'no'}`);
          lines.push('');
          lines.push('| Scenario | Status | Duration | HTTP p95 | HTTP p99 | HTTP error rate |');
          lines.push('|----------|--------|----------|----------|----------|-----------------|');

          for (const scenario of report.scenarios ?? []) {
            const status = scenario.passed ? 'pass' : 'fail';
            const duration = `${(Number(scenario.durationMs) / 1000).toFixed(1)}s`;
            const httpP95 =
              scenario.metrics?.httpP95 == null
                ? 'N/A'
                : `${Number(scenario.metrics.httpP95).toFixed(1)}ms`;
            const httpP99 =
              scenario.metrics?.httpP99 == null
                ? 'N/A'
                : `${Number(scenario.metrics.httpP99).toFixed(1)}ms`;
            const errorRate =
              scenario.metrics?.httpErrorRate == null
                ? 'N/A'
                : `${(Number(scenario.metrics.httpErrorRate) * 100).toFixed(2)}%`;
            lines.push(`| ${scenario.id} | ${status} | ${duration} | ${httpP95} | ${httpP99} | ${errorRate} |`);
          }

          fs.appendFileSync(summaryPath, `${lines.join('\n')}\n`);
          NODE

      - name: Publish nightly pglite load trend summary
        if: always()
        run: |
          if [ ! -f load-nightly-pglite-trend.json ]; then
            exit 0
          fi

          node - <<'NODE'
          const fs = require('fs');
          const summaryPath = process.env.GITHUB_STEP_SUMMARY;
          const trend = JSON.parse(fs.readFileSync('load-nightly-pglite-trend.json', 'utf8'));

          const lines = [];
          lines.push('## Nightly Pglite Load Trend');
          lines.push('');
          lines.push(`- History files: ${trend.historySummaryCount}`);
          lines.push(`- Regression change-point: ${trend.hasRegressionChangePoint ? 'yes' : 'no'}`);
          lines.push(`- Insufficient history: ${trend.hasInsufficientHistory ? 'yes' : 'no'}`);
          lines.push('');
          lines.push('| Metric | Current | Hist Median | Delta | Robust Z | Hist N | Status |');
          lines.push('|--------|---------|-------------|-------|----------|--------|--------|');

          for (const metric of trend.metrics) {
            const isRate = metric.metric.endsWith('/httpErrorRate');
            const current = isRate
              ? (metric.current == null ? 'N/A' : `${metric.current >= 0 ? '+' : ''}${(Number(metric.current) * 100).toFixed(1)}%`)
              : Number(metric.current).toFixed(1) + 'ms';
            const histMedian = metric.historyMedian == null
              ? 'N/A'
              : isRate
                ? `${metric.historyMedian >= 0 ? '+' : ''}${(Number(metric.historyMedian) * 100).toFixed(1)}%`
                : Number(metric.historyMedian).toFixed(1) + 'ms';
            const delta =
              metric.deltaPercent == null
                ? 'N/A'
                : `${metric.deltaPercent >= 0 ? '+' : ''}${(Number(metric.deltaPercent) * 100).toFixed(1)}%`;
            const robustZ =
              metric.robustZ == null ? 'N/A' : Number(metric.robustZ).toFixed(2);
            const status = metric.insufficientHistory
              ? 'insufficient-history'
              : metric.regressionChangePoint
                ? 'regression-change-point'
                : metric.improvementChangePoint
                  ? 'improvement-change-point'
                  : 'stable';

            lines.push(
              `| ${metric.metric} | ${current} | ${histMedian} | ${delta} | ${robustZ} | ${metric.historyCount} | ${status} |`
            );
          }

          fs.appendFileSync(summaryPath, `${lines.join('\n')}\n`);
          NODE

  runtime-browser:
    needs: changes
    if: needs.changes.outputs.runtime == 'true' || github.event_name == 'workflow_dispatch'
    runs-on: blacksmith-4vcpu-ubuntu-2404
    timeout-minutes: 15
    strategy:
      matrix:
        browser: [chromium, firefox]
    steps:
      - uses: actions/checkout@v4
      - uses: ./.github/actions/setup-environment

      - name: Install Playwright ${{ matrix.browser }}
        run: bunx playwright install --with-deps ${{ matrix.browser }}

      - name: Run browser runtime tests
        env:
          PLAYWRIGHT_BROWSER: ${{ matrix.browser }}
        run: bun test:runtime:browser

  demo-smoke:
    needs: changes
    if: needs.changes.outputs.demo == 'true' || github.event_name == 'workflow_dispatch'
    runs-on: blacksmith-4vcpu-ubuntu-2404
    timeout-minutes: 20
    steps:
      - uses: actions/checkout@v4
      - uses: ./.github/actions/setup-environment

      - name: Install Playwright Chromium
        run: bunx playwright install --with-deps chromium

      - name: Run demo split-screen smoke test
        run: bun test:runtime:demo

  runtime-cloudflare:
    runs-on: blacksmith-4vcpu-ubuntu-2404
    timeout-minutes: 10
    steps:
      - uses: actions/checkout@v4
      - uses: ./.github/actions/setup-environment

      - name: Run Cloudflare Worker runtime tests
        run: bun test:runtime:cloudflare

  runtime-d1:
    runs-on: blacksmith-4vcpu-ubuntu-2404
    timeout-minutes: 10
    steps:
      - uses: actions/checkout@v4
      - uses: ./.github/actions/setup-environment

      - name: Run D1 runtime tests
        run: bun test:runtime:d1

  runtime-node:
    runs-on: blacksmith-4vcpu-ubuntu-2404
    timeout-minutes: 10
    steps:
      - uses: actions/checkout@v4
      - uses: ./.github/actions/setup-environment

      - name: Install better-sqlite3 for Node
        run: |
          mkdir -p /tmp/better-sqlite3 && cd /tmp/better-sqlite3
          npm init -y > /dev/null 2>&1
          npm install better-sqlite3
          ln -sf /tmp/better-sqlite3/node_modules/better-sqlite3 $GITHUB_WORKSPACE/node_modules/better-sqlite3

      - name: Run Node.js runtime tests
        run: bun test:runtime:node

  runtime-deno:
    runs-on: blacksmith-4vcpu-ubuntu-2404
    timeout-minutes: 10
    steps:
      - uses: actions/checkout@v4
      - uses: ./.github/actions/setup-environment

      - name: Install Deno
        uses: denoland/setup-deno@v2
        with:
          deno-version: v2.x

      - name: Run Deno runtime tests
        run: bun test:runtime:deno

  runtime-electron:
    needs: changes
    if: needs.changes.outputs.runtime_electron == 'true' || github.event_name == 'workflow_dispatch'
    runs-on: blacksmith-4vcpu-ubuntu-2404
    timeout-minutes: 10
    steps:
      - uses: actions/checkout@v4
      - uses: ./.github/actions/setup-environment

      - name: Run Electron runtime bridge tests
        run: bun test:runtime:electron

  maestro-ios:
    needs: changes
    if: needs.changes.outputs.expo == 'true' || github.event_name == 'workflow_dispatch'
    runs-on: macos-latest
    timeout-minutes: 45
    steps:
      - uses: actions/checkout@v4
      - uses: ./.github/actions/setup-environment

      - name: Install Maestro
        run: |
          curl -fsSL https://get.maestro.mobile.dev | bash
          echo "$HOME/.maestro/bin" >> "$GITHUB_PATH"

      - name: Start Metro (dev client)
        working-directory: tests/expo-app
        run: |
          bun run start:dev-client > metro.log 2>&1 &
          echo $! > metro.pid
          for i in {1..60}; do
            if nc -z 127.0.0.1 8081; then
              exit 0
            fi
            sleep 1
          done
          cat metro.log
          exit 1

      - name: Build + install iOS app
        working-directory: tests/expo-app
        run: bun run ios:build

      - name: Run Maestro flows
        working-directory: tests/expo-app
        run: bun run maestro:test

      - name: Stop Metro
        if: always()
        working-directory: tests/expo-app
        run: |
          if [ -f metro.pid ]; then
            kill "$(cat metro.pid)" || true
          fi
          cat metro.log || true
